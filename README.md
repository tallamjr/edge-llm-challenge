### Edge-Device Large Language Model Competition NeurIPS 2024 Challenge üì±

### Track 1 üóúÔ∏è

Compression Challenge: teams are tasked with developing their own compression
methods to compress three pre-trained LLMs individually: Phi-2, Llama-3-8B, and
Qwen-7B. Each model submitted must be capable of running on a smartphone device
with 12 GB DRAM. Each model will be evaluated on a subset of the OpenCompass
benchmark, which comprehensively assesses LLMs across multiple fundamental
dimensions. For each task, the final submission score will be determined by
calculating the average score of the three models involved.

**Please note that quantization methods are not allowed** since 8-bit or 4-bit
quantization for LLMs is a well-established technique. Participants must submit
models in FP16 or FP32 format.
